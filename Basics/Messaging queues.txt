Consumers:-
    -Sometimes we want to join the stream processing to a node. We use Consumer
    -Apache Flink
        -It is an in memory based consumer but it guarantees that each message only affects state once
        -Other consumers are Spark streaming, Tex, Storm
        -Flink is realtime
        -Also they can be handled with code what kind of join and how to consume
        -How flink ensures that each message is processed at least and also exactly once? It uses a job manager which checkpoints the current state in s3URL
